{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_probability as tfp\n",
    "tfb = tfp.bijectors\n",
    "from gp_models import CustomKernel,GP_model, GPR_model, GPR_analytical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1058, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to import S&P500 call option data and match them with daily S&P500 \n",
    "# and VIX levels from Yahoo Finance\n",
    "\n",
    "paths = ['vix_data/SPX_Index/SPX_30DAY_IMPVOL_allMNY.csv','vix_data/SPX_Index/SPX_60DAY_IMPVOL_allMNY.csv'\n",
    "        ,'vix_data/SPX_Index/SPX_3MTH_IMPVOL_allMNY.csv','vix_data/SPX_Index/SPX_6MTH_IMPVOL_allMNY.csv'\n",
    "        ,'vix_data/SPX_Index/SPX_12MTH_IMPVOL_allMNY.csv']\n",
    "\n",
    "df = pd.read_csv('vix_data/SPX_Index/SPX_30DAY_IMPVOL_allMNY.csv')\n",
    "\n",
    "maturities = [30,60,90,180,360]\n",
    "m = 0\n",
    "cols = ['date', 'XDAY_IMPVOL_80.MNY_DF', 'XDAY_IMPVOL_90.0.MNY_DF',\n",
    "       'XDAY_IMPVOL_95.0.MNY_DF', 'XDAY_IMPVOL_97.5.MNY_DF',\n",
    "       'XDAY_IMPVOL_100.0.MNY_DF', 'XDAY_IMPVOL_102.5.MNY_DF',\n",
    "       'XDAY_IMPVOL_105.0.MNY_DF', 'XDAY_IMPVOL_110.0.MNY_DF',\n",
    "       'XDAY_IMPVOL_120.MNY_DF', 'Date', 'tau', 'mid_spx', 'mid_vix']\n",
    "df0 = pd.DataFrame(columns=cols)\n",
    "vix = yf.Ticker(\"^VIX\")\n",
    "sp500 = yf.Ticker(\"^GSPC\")\n",
    "\n",
    "start_date = datetime.datetime(2017,1,1)\n",
    "\n",
    "for p in paths:\n",
    "    df = pd.read_csv(p)\n",
    "    df.columns = cols[:-4]\n",
    "    df['Date'] =df.date.apply(datetime.datetime.strptime,args = ('%Y-%m-%d',))\n",
    "    \n",
    "    df = df[df['Date']>start_date]\n",
    "    df['tau'] = maturities[m]\n",
    "    end_of_data = df['Date'].iloc[-1]\n",
    " \n",
    "    n_days = int((datetime.datetime.now()-start_date).days)\n",
    "    period = str(n_days)+'d'\n",
    "    df_spx = sp500.history(period=period).iloc[:,:-2].reset_index()\n",
    "    df_spx['mid_spx'] = 1/2*(df_spx.High+df_spx.Low)\n",
    "\n",
    "    df_vix = vix.history(period=period).iloc[:,:-2].reset_index()\n",
    "    df_vix['mid_vix'] = 1/2*(df_vix.High+df_vix.Low)\n",
    "\n",
    "    df_spx = df_spx[df_spx['Date']<end_of_data+datetime.timedelta(days=1)]\n",
    "    df_vix = df_vix[df_vix['Date']<end_of_data+datetime.timedelta(days=1)]\n",
    "\n",
    "    spx = df_spx[['Date','mid_spx']]\n",
    "    vixx = df_vix[['Date','mid_vix']]\n",
    "\n",
    "    df_all = pd.merge(df,spx,on='Date')\n",
    "    df_all = pd.merge(df_all,vixx,on='Date')\n",
    "\n",
    "    df0 = pd.concat([df0,df_all],axis=0)\n",
    "    m+=1\n",
    "    break\n",
    "    \n",
    "df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the training data input points matrix\n",
    "last_day = datetime.datetime(2017,7,1)\n",
    "include_swap = True\n",
    "\n",
    "# Use this to select just one value of time to maturity\n",
    "maturity = 30\n",
    "df_all = df0[df0['tau']==maturity]\n",
    "df_train = df_all[df_all['Date']<last_day]\n",
    "\n",
    "# Use this to keep multiple values of tau and the tau column\n",
    "# df_train = df0[df0['Date']<last_day]\n",
    "\n",
    "# Use this to add a timestamp to the datapoints\n",
    "# df_train['t'] = np.arange(1,len(df_train)+1)\n",
    "\n",
    "# Drop the date columns as they are not inputs to the model\n",
    "df_train = df_train.drop(['Date','date'],axis=1)\n",
    "\n",
    "# Sample one day out of two to reduce data size\n",
    "df_train = df_train.iloc[::2,:]\n",
    "n_days = df_train.shape[0]\n",
    "\n",
    "# Match SPX and VIX data to option prices per day (9 quoted prices per day)\n",
    "columns_to_keep = ['mid_spx','mid_vix'] # '['tau','mid_spx','mid_vix']' or ['mid_spx','mid_vix','t']\n",
    "moneyness = np.array([80,90,95,97.5,100,102.5,105,110,120])\n",
    "\n",
    "indices = df_train[columns_to_keep].values\n",
    "indices = np.repeat(indices,len(moneyness),axis=0)\n",
    "\n",
    "mny = np.tile(moneyness,n_days)\n",
    "# Observations\n",
    "y = df_train.loc[:,:'XDAY_IMPVOL_120.MNY_DF'].values.flatten()\n",
    "# Inputs\n",
    "X = np.concatenate([np.reshape(mny,[-1,1]),indices],axis=1)\n",
    "\n",
    "if not include_swap:\n",
    "    X = X[:,:-1]\n",
    "    X_test = X_test[:,:-1]\n",
    "\n",
    "# Convert to tensor\n",
    "X = tf.constant(X,dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all hyperparameters as trainable TensorFlow Variables\n",
    "# Note that the length of the length_scales list must be equal to the input dimension\n",
    "\n",
    "process_variance = 32\n",
    "noise_variance = 0.18\n",
    "length_scales =[12.7,502]\n",
    "length_scales = [12.7,502,16.08]\n",
    "length_scales = [12.7,65,270]\n",
    "lower_bounds = [0.01,10]\n",
    "upper_bounds = [3,50]\n",
    "trend_coef = [[1,1]]\n",
    "if include_swap:\n",
    "    lower_bounds.append(0.001)\n",
    "    upper_bounds.append(2.)\n",
    "    length_scales.append(16.08)\n",
    "    #length_scales.append(20)\n",
    "    \n",
    "    trend_coef[0].append(1)\n",
    "# Mean function hyperparameters\n",
    "b0 = tf.Variable(16.59,dtype=tf.float64, name = 'b0') \n",
    "b1 = tf.Variable(1,dtype=tf.float64, name= 'b1')\n",
    "b2 = tf.Variable(1,dtype=tf.float64, name= 'b2')\n",
    "b = tf.Variable(trend_coef,dtype=tf.float64, name= 'b')\n",
    "# Kernel hyperparameters\n",
    "sp = tfp.util.TransformedVariable(process_variance, tfb.Exp(), dtype=tf.float64, name='sigma_process')\n",
    "sn2 = tfp.util.TransformedVariable(noise_variance, tfb.Exp(), dtype=tf.float64, name='sigma_noise2')\n",
    "scales = tf.Variable(length_scales,dtype=tf.float64)#,constraint = lambda x: tf.clip_by_value(x,lower_bounds,upper_bounds))#,dtype=tf.float64, name = 'length_scales')\n",
    "\n",
    "# Define custom kernel\n",
    "kernel_family = 'M52'\n",
    "param ={'amp' : sp , 'scales': scales,'family' : kernel_family}\n",
    "my_kernel = CustomKernel(1,parameters = param)\n",
    "\n",
    "#Define mean function\n",
    "#def mean_f(x): return tf.squeeze(b0 + tf.linalg.matmul(x, b, transpose_b=True))\n",
    "def mean_f(x): return b0 \n",
    "#def mean_f(x): return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and fit the model\n",
    "GP = GP_model(my_kernel, index_points=X,mean_fn=mean_f, beta=(b0,b),observation_noise_variance=sn2,jitter=1e-06, name='GP')\n",
    "GP.fit(y,n_iters=500,verbose=True,optimizer = tf.optimizers.Adam(0.01))\n",
    "print('\\n## Trained Hyperparameters ##\\n')\n",
    "print(sp)\n",
    "print(scales)\n",
    "print(sn2)\n",
    "print(b0)\n",
    "#GP.hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-07-10'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a day to test the predictions on\n",
    "# 'future' indicates how many days after the last training day the test set is chosen\n",
    "future = 4\n",
    "n_days = df_train.shape[0]*2\n",
    "test_date = df_all.iloc[n_days+future-1,0]\n",
    "df_test = df_all.iloc[n_days+future-1,1:].drop(['Date'])\n",
    "y_test = df_test[:9].values\n",
    "\n",
    "# Choose between timestamped or unmarked data\n",
    "X_test = np.array([moneyness,np.ones(9)*df_test['mid_spx'],np.ones(9)*df_test['mid_vix']]).T\n",
    "\n",
    "t_test = X[-1,-1]+future\n",
    "X_test = np.array([moneyness,np.ones(9)*df_test['mid_spx'],np.ones(9)*df_test['mid_vix'],\n",
    "                 np.ones(9)*t_test]).T\n",
    "test_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a GP Regression model with learned parameters, scalar noise variance\n",
    "GPR = GPR_model(my_kernel,X_test,X,y,observation_noise_variance=sn2,predictive_noise_variance=None,mean_fn=mean_f,jitter=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPR model with vector of noise variances (the code to find the weights is further down)\n",
    "weights = tf.constant(np.linspace(9,0.1,int(n_days/2)),dtype=tf.float64)\n",
    "nugget = weights*sn2\n",
    "new_sn2 = tf.repeat(nugget,9)\n",
    "\n",
    "GPR = GPR_model(my_kernel,X_test,X,y,observation_noise_variance=new_sn2,predictive_noise_variance=sn2,mean_fn=mean_f,jitter=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions, confidence bounds and market implied volatility for test set\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "plt.scatter(moneyness,GPR.price(),marker='x',c='r',label='GP estimate')\n",
    "plt.plot(moneyness,GPR.bounds_price(0.95)[0],'--',c='black',label = '95% confidence bounds')\n",
    "plt.plot(moneyness,GPR.bounds_price(0.95)[1],'--',c='black')\n",
    "plt.plot(moneyness,y_test,label='Market Implied Volatility')\n",
    "plt.legend()\n",
    "plt.xlabel('Moneyness')\n",
    "plt.ylabel('Implied volatility')\n",
    "rmse = np.sqrt(mse(y_test,GPR.price()))\n",
    "plt.title('RMSE = '+str(round(rmse,4)))\n",
    "fig_path = '/Users/danielmontagna/Documents/ETHZ/PH-MA3/Thesis/Report/thesis/Figures/VIX/'\n",
    "fig_name = 'pred_5days_cumul_m52.pdf'\n",
    "fig_path += fig_name\n",
    "#plt.savefig(fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test predictions for model with different maturities as inputs\n",
    "\n",
    "error_array = np.zeros([50,5])\n",
    "dates = np.unique(df0[df0['Date']>last_day].Date)\n",
    "for i in range(50):\n",
    "    the_day = last_day + datetime.timedelta(days=i+1)\n",
    "    the_day = dates[i]\n",
    "    df_test = df0[df0['Date']==the_day]\n",
    "\n",
    "    m = 0\n",
    "    errs =[]\n",
    "    for mat in maturities:\n",
    "        y_test = df_test.iloc[m,1:10]\n",
    "        X_test = np.array([moneyness,mat*np.ones(9),np.ones(9)*df_test['mid_spx'].mean()\n",
    "                           ,np.ones(9)*df_test['mid_vix'].mean()]).T\n",
    "        GPR = GPR_model(my_kernel,X_test,X,y,observation_noise_variance=sn2\n",
    "                    ,predictive_noise_variance=None,mean_fn=mean_f,jitter=1e-6) \n",
    "#         plt.plot(moneyness,y_test,'--',label=r'$\\tau =$ '+str(mat)+ ' days')\n",
    "#         plt.scatter(moneyness,GPR.mean(),marker='d')\n",
    "        errs.append(mse(y_test,GPR.mean()))\n",
    "        m+=1\n",
    "    error_array[i,:] = np.array(errs)\n",
    "# plt.legend()\n",
    "# plt.xlabel('Moneyness')\n",
    "# plt.ylabel('Implied Volatility')\n",
    "# #plt.show()\n",
    "# fig_path = '/Users/danielmontagna/Documents/ETHZ/PH-MA3/Thesis/Report/thesis/Figures/VIX/'\n",
    "# fig_name = 'pred_5days_5taus.pdf'\n",
    "# fig_path += fig_name\n",
    "#plt.savefig(fig_path)\n",
    "print(np.mean(error_array,axis=0))\n",
    "error_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions for different maturities for one day on the same graph\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "future = 4\n",
    "n_days = df_train.shape[0]*2\n",
    "\n",
    "test_date = df0[df0['tau']==mat].iloc[40+future,0]\n",
    "df_test = df0[df0['tau']==mat].iloc[40+future,1:].drop(['Date'])\n",
    "for mat in maturities:\n",
    "    y_test = df_test[:9].values\n",
    "    X_test = np.array([moneyness,mat*np.ones(9),np.ones(9)*df_test['mid_spx'],np.ones(9)*df_test['mid_vix']]).T\n",
    "    gpr = GPR_model(my_kernel,X_test,X,y,observation_noise_variance=sn2,predictive_noise_variance=None,mean_fn=mean_f,jitter=1e-6)\n",
    "\n",
    "    plt.plot(moneyness,gpr.mean(),'d')\n",
    "    plt.plot(moneyness,y_test,'--')\n",
    "    erri = np.sqrt(mse(y_test,gpr.mean()))\n",
    "print(np.mean(erri))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search to find w_max and w_min\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "width = 10\n",
    "cross_val = np.zeros([width,width])\n",
    "maxs = np.linspace(1,10,width)\n",
    "mins = np.linspace(0.1,1,width)\n",
    "j = 0\n",
    "future = 5\n",
    "for wmin in mins:\n",
    "    k= 0\n",
    "    for wmax in maxs:\n",
    "        errs = []\n",
    "        weights = tf.constant(np.linspace(wmax,wmin,int(n_days/4)),dtype=tf.float64)\n",
    "        nugget = weights*sn2\n",
    "        new_sn2 = tf.repeat(nugget,9)\n",
    "        #for i in range(10):\n",
    "        half = 62\n",
    "\n",
    "        df_test = df_all.iloc[half:half+future,1:].drop(['Date'],axis=1)\n",
    "        y_test = df_test.iloc[:,:9].values.flatten()\n",
    "        indices = df_test.iloc[:,-2:].values\n",
    "        indices = np.repeat(indices,len(moneyness),axis=0)\n",
    "\n",
    "        mny = np.tile(moneyness,future)\n",
    "\n",
    "        X_test = np.concatenate([np.reshape(mny,[-1,1]),indices],axis=1)\n",
    "\n",
    "        end = (31)*9\n",
    "            \n",
    "        GPR = GPR_model(my_kernel,X_test,X[:end,:],y[:end],observation_noise_variance=new_sn2,predictive_noise_variance=sn2,mean_fn=mean_f,jitter=1e-6)\n",
    "\n",
    "        err=mse(y_test,GPR.price())\n",
    "            #errs.append(err)\n",
    "        #cross_val[j,k]=np.mean(errs)\n",
    "        cross_val[j,k]=err\n",
    "        \n",
    "        k+=1\n",
    "    j+=1\n",
    "# print('AVG RMSE = ',np.mean(errs))\n",
    "# print('MAX = ',np.max(errs))\n",
    "# print('MIN = ',np.min(errs))\n",
    "# plt.plot(ws,cross_val,'d',label = 'RMSE')\n",
    "# plt.xlabel('$w_{min}$',fontsize='14')\n",
    "# plt.ylabel('AVG RMSE (14 days)')\n",
    "# plt.legend()\n",
    "# fig_path = '/Users/danielmontagna/Documents/ETHZ/PH-MA3/Thesis/Report/thesis/Figures/VIX/'\n",
    "# fig_path+= 'grid_search_wmax.pdf'\n",
    "# plt.tight_layout()\n",
    "#plt.savefig(fig_path)\n",
    "\n",
    "cross_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.constant(np.linspace(10,0.1,int(n_days/2)),dtype=tf.float64)\n",
    "nugget = weights*sn2\n",
    "new_sn2 = tf.repeat(nugget,9)\n",
    "new_sn2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results of the grid search\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "YY,XX = np.meshgrid(maxs,mins)\n",
    "ZZ = cross_val\n",
    "ax.plot_surface(YY,XX,ZZ,cmap = cm.coolwarm)\n",
    "ax.set_xlabel(r'$w_{max}$',fontsize='14')\n",
    "ax.set_ylabel(r'$w_{min}$',fontsize='14')\n",
    "ax.set_zlabel('MSE',rotation='90')\n",
    "\n",
    "plt.savefig('/Users/danielmontagna/Documents/ETHZ/PH-MA3/Thesis/Report/thesis/Figures/VIX/w_surface.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average RMSE over a period following the training data ( e.g. D_m +7 or D_m +50) \n",
    "\n",
    "weights = tf.constant(np.linspace(9,0.1,int(n_days/2)),dtype=tf.float64)\n",
    "\n",
    "nugget = weights*sn2\n",
    "new_sn2 = tf.repeat(nugget,9)\n",
    "errs=[]\n",
    "for i in np.arange(1,7):\n",
    "    future = i\n",
    "    df_test = df_all.iloc[n_days+future-1,1:].drop(['Date'])\n",
    "\n",
    "    y_test = df_test[:9].values\n",
    "    #X_test = np.array([moneyness,np.ones(9)*df_test['mid_spx'],np.ones(9)*df_test['mid_vix']]).T\n",
    "    t_test = X[-1,-1]+future\n",
    "    X_test = np.array([moneyness,np.ones(9)*df_test['mid_spx'],np.ones(9)*df_test['mid_vix'],\n",
    "                 np.ones(9)*t_test]).T\n",
    "    #Define a GPR model with scalar noise (sn2) or vector valued noise (new_sn2)\n",
    "    GPR = GPR_model(my_kernel,X_test,X,y,observation_noise_variance=new_sn2,predictive_noise_variance=None,mean_fn=mean_f,jitter=1e-6)\n",
    "    #GPR = GPR_model(my_kernel,X_test,X,y,observation_noise_variance=sn2,predictive_noise_variance=sn2,mean_fn=mean_f,jitter=1e-6)\n",
    "\n",
    "    rmse = np.sqrt(mse(y_test,GPR.price()))\n",
    "    errs.append(rmse)\n",
    "print('AVG RMSE = ',np.mean(errs))\n",
    "print('MAX = ',np.max(errs))\n",
    "print('MIN = ',np.min(errs))\n",
    "print('MEDIAN = ',np.median(errs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot historical S&P500 and VIX levels\n",
    "\n",
    "df_spx = sp500.history(period=period,interval='1d').iloc[:,:-2].reset_index()\n",
    "df_spx['mid_spx'] = 1/2*(df_spx.High+df_spx.Low)\n",
    "\n",
    "df_vix = vix.history(period=period,interval='1d').iloc[:,:-2].reset_index()\n",
    "df_vix['mid_vix'] = 1/2*(df_vix.High+df_vix.Low)\n",
    "\n",
    "last_day = datetime.datetime(2017,10,1)\n",
    "\n",
    "df_spx = df_spx[df_spx['Date']<last_day+datetime.timedelta(days=1)]\n",
    "df_vix = df_vix[df_vix['Date']<last_day+datetime.timedelta(days=1)]\n",
    "\n",
    "df_spx = df_spx[df_spx['Date']>start_date-datetime.timedelta(days=1)]\n",
    "df_vix = df_vix[df_vix['Date']>start_date-datetime.timedelta(days=1)]\n",
    "\n",
    "\n",
    "# df_spx = df_spx.iloc[:-275,:]\n",
    "# df_vix = df_vix.iloc[:-275,:]\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('S&P 500')\n",
    "days = np.arange(df_spx.shape[0])\n",
    "\n",
    "ax1.plot(np.arange(df_spx.shape[0]),df_spx.mid_spx,c='black',label = 'S&P 500')\n",
    "months = ['01/2017','02/2017','03/2017','04/2017','05/2017','06/2017','07/2017','08/2017','09/2017']\n",
    "plt.xticks(ticks = np.arange(0,len(days),22),labels = months,rotation = 70)\n",
    "ax2 = ax1.twinx() \n",
    "ax2.set_ylabel('VIX')\n",
    "ax2.plot(days,df_vix.mid_vix,c='tab:blue',label='VIX')\n",
    "ax2.vlines(133,9,16,linestyles='dashed',colors='red')\n",
    "ax2.legend()\n",
    "ax1.legend()\n",
    "fig.tight_layout()\n",
    "plt.savefig('index_history_2017.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
